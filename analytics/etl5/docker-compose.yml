version: '3'
networks:
  etl-network:
    driver: bridge

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    networks:
      - etl-network

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - zookeeper
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    ports:
      - "9093:9092"
    networks:
      - etl-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server kafka:9092 --list || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 10

  postgres:
    image: debezium/postgres:14
    environment:
      POSTGRES_DB: mydb
      POSTGRES_USER: user
      POSTGRES_PASSWORD: password
    ports:
      - "5433:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./postgres-init:/docker-entrypoint-initdb.d
    command: >
      postgres
      -c wal_level=logical
      -c max_replication_slots=10
      -c max_wal_senders=10
    networks:
      - etl-network

  connect:
    image: debezium/connect:2.3
    depends_on:
      - kafka
      - postgres
    environment:
      BOOTSTRAP_SERVERS: kafka:9092
      GROUP_ID: connect-cluster
      CONFIG_STORAGE_TOPIC: connect-configs
      OFFSET_STORAGE_TOPIC: connect-offsets
      STATUS_STORAGE_TOPIC: connect-status
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
    ports:
      - "8083:8083"
    networks:
      - etl-network
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8083/" ]
      interval: 10s
      timeout: 5s
      retries: 10

  clickhouse:
    image: clickhouse/clickhouse-server:23.3
    ports:
      - "8123:8123"
      - "9002:9000"
    healthcheck:
      test: ["CMD-SHELL", "clickhouse-client --host localhost --query \"SELECT 1\""]
      interval: 5s
      timeout: 5s
      retries: 10
    networks:
      - etl-network

  clickhouse-init:
    image: clickhouse/clickhouse-server:23.3
    depends_on:
      clickhouse:
        condition: service_healthy
    volumes:
      - ./clickhouse-init/init.sql:/init.sql:ro
    entrypoint:
      - bash
      - -c
      - |
        until clickhouse-client --host clickhouse --query "SELECT 1"; do
          echo "Waiting for ClickHouse..."
          sleep 2
        done
        clickhouse-client --host clickhouse --multiquery < /init.sql
    networks:
      - etl-network

  spark-master:
    image: bitnami/spark:3.5.0
    hostname: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark-master
      - SPARK_MASTER_PORT=7077
      - SPARK_MASTER_WEBUI_PORT=8080
      - SPARK_LOCAL_IP=spark-master
    ports:
      - "7077:7077"
      - "8080:8080"
    volumes:
      - ./spark-app:/app
    networks:
      - etl-network
    command: bash -c "pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r /app/requirements.txt && /opt/bitnami/scripts/spark/run.sh"

  spark-worker:
    image: bitnami/spark:3.5.0
    hostname: spark-worker
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
      - SPARK_LOCAL_IP=spark-worker
    networks:
      - etl-network

  kafka-setup:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      bash -c "
      kafka-topics --create --if-not-exists --topic pgserver.public.users_events --partitions 1 --replication-factor 1 --bootstrap-server kafka:9092;
      kafka-topics --create --if-not-exists --topic pgserver.public.session_events --partitions 1 --replication-factor 1 --bootstrap-server kafka:9092;
      kafka-topics --create --if-not-exists --topic pgserver.public.playlist_events --partitions 1 --replication-factor 1 --bootstrap-server kafka:9092
      "
    networks:
      - etl-network

  connect-setup:
    image: curlimages/curl:8.5.0
    depends_on:
      connect:
        condition: service_healthy
    volumes:
      - ./connector-config.json:/connector-config.json
    entrypoint:
      - sh
      - -c
      - |
        until curl -s http://connect:8083/; do
          echo "Waiting for Kafka Connect..."
          sleep 2
        done
        curl -X POST -H "Content-Type: application/json" --data @/connector-config.json http://connect:8083/connectors
    networks:
      - etl-network

  superset:
    image: apache/superset:latest
    ports:
      - "8088:8088"
    networks:
      - etl-network
    depends_on:
      - clickhouse
    environment:
      SUPERSET_SECRET_KEY: your-secret-key
      SUPERSET_LOAD_EXAMPLES: "no"
    volumes:
      - superset-data:/app/superset_home
    command: >
      bash -c "
      pip install -i https://pypi.tuna.tsinghua.edu.cn/simple clickhouse-connect==0.6.20 &&
      superset db upgrade &&
      superset fab create-admin --username admin --firstname Superset --lastname Admin --email admin@superset.com --password admin &&
      superset init &&
      /usr/bin/run-server.sh
      "


volumes:
  postgres-data:
  superset-data: